{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd      #IMPORTANTE NO OLVIDAR ヽ(•‿ •)ノ\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_rows\", 5) # Especificar el número de filas a mostrar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomar datos de Excel \n",
    "Utilizaremos la función read_excel para leer los datos de un archivo de Excel. La función le permite leer en pestañas específicas por nombre o ubicación.\n",
    "https://pandas.pydata.org/pandas-docs/stable/io.html#excel-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubicación del archivo \n",
    "Ubicación  =  r 'C: \\ Users \\ david \\ notebooks \\ update \\ Lesson3.xlsx'\n",
    "\n",
    "# Analizar una hoja específica \n",
    "df  =  pd . read_excel ( Location ,  0 ,  index_col = 'StatusDate' ) \n",
    "df . dtypes\n",
    "\n",
    "df.to_excel('foo.xlsx', sheet_name='Sheet1')\n",
    "pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestra tarea ahora es crear un nuevo marco de datos que comprima los datos para que tengamos recuentos diarios de clientes por estado y fecha de estado. Podemos ignorar la columna Estado ya que todos los valores en esta columna son de valor 1 . Para lograr esto, utilizaremos las funciones del grupo de datos groupby y sum () .\n",
    "\n",
    "Tenga en cuenta que tuvimos que usar reset_index . Si no lo hiciéramos, no habríamos sido capaces de agrupar tanto el Estado como el StatusDate dado que la función groupby espera solo columnas como entradas. La función reset_index devolverá el índice StatusDate a una columna en el marco de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por estado y fecha de estado \n",
    "diario  =  df . reset_index () . groupby ([ '' State ' , ' StatusDate ' ]) . sum () \n",
    "Diario . cabeza ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos la transformación de atributo en lugar de aplicar . El motivo es que la transformación mantendrá la misma forma (número de filas y columnas) del marco de datos y no se aplicará. Al observar los gráficos anteriores, podemos darnos cuenta de que no se parecen a una distribución gaussiana, esto significa que no podemos usar estadísticas de resumen como la media y stDev. Usamos percentiles en su lugar. Tenga en cuenta que corremos el riesgo de eliminar buenos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular valores atípicos \n",
    "StateYearMonth  =  Diario . GroupBy ([ Daily . Índice . get_level_values ( 0 ),  Daily . Índice . get_level_values ( 1 ) . años ,  Daily . Índice . get_level_values ( 1 ) . meses ]) \n",
    "Daily [ 'Baja' ]  =  StateYearMonth [ 'CustomerCount' ] . transformar ( lambda  x :  x . cuantil ( q = .25 )  -  ( 1.5 * x . cuantil ( q = .75 ) - x . cuantil ( q = .25 ))  ) \n",
    "Diario [ 'Superior' ]  =  StateYearMonth [ 'CustomerCount' ] . transformar (  lambda  x :  x . cuantil ( q =.75 )  +  ( 1.5 * x . Cuantil ( q = .75 ) - x . Cuantil ( q = .25 ))  ) \n",
    "Diariamente [ 'Anormalidad' ]  =  ( Diaria [ 'CustomerCount' ]  <  Diaria [ 'Inferior' ])  |  ( Diario [ 'CustomerCount' ]  >  Diario [ 'Upper' ]) \n",
    "\n",
    "# Eliminar valores atípicos \n",
    "diarios  =  Diario [ Diario [ 'Atípico' ]  ==  Falso ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_values  =  [ 'NO CLUE' ,  'N / A' ,  '0' ] \n",
    "requests  =  pd . read_csv ( '../data/311-service-requests.csv' ,  na_values = na_values ,  dtype = { 'Incident Zip' :  str })\n",
    "solicita [ 'Incident Zip' ] . único ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir un objeto en grupos \n",
    "https://pandas.pydata.org/pandas-docs/stable/groupby.html#groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusionar, unir y concatenar\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/merging.html#merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gráficas\n",
    "https://pandas.pydata.org/pandas-docs/stable/visualization.html#visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulación de datos perdidos IMPORTANTE ヽ(•‿ •)ノ\n",
    "\n",
    "Los datos perdidos son representados de forma general como: null, NaN o NA value.\n",
    "\n",
    "La identificación de datos atípicos puede hacerse de dos maneras:\n",
    "\n",
    "Mediante la creación de una máscara de valores logícos para indicar la posición del valor perdido\n",
    "\n",
    "Especificando un valor centinela (None o NaN en python) para identificar los valores perdidos\n",
    "https://pandas.pydata.org/pandas-docs/stable/missing_data.html#missing-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para identificar las observaciones perdidas se acude a isnull() y notnull(), donde juntos regresan una máscara de valores booleanos\n",
    "df=pd.Series([1,np.nan,7,None])\n",
    "print(df.notnull())\n",
    "print(\"\\n\",df[df.notnull()]) # Utilizando la máscara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En el caso de un DataFrame la eliminación no se puede realizar por valores ヽ(•‿ •)ノ\n",
    "# Se debe eliminar la columna o fila completa\n",
    "\n",
    "df=pd.DataFrame([[1,      np.nan, 2],\n",
    "                   [2,      3,      5],\n",
    "                   [np.nan, 4,      6]])\n",
    "print(df)\n",
    "print(\"\\n\",df.dropna(axis=0)) # Eliminar por filas\n",
    "print(\"\\n\",df.dropna(axis=1)) # Eliminar por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede especificar un número mínimo de valores perdidos antes de elimar una fila o columna\n",
    "df[3]=np.nan\n",
    "print(df)\n",
    "print(\"\\n\",df.dropna(axis=0,thresh=1)) # Mínimo de valores no NaN por fila\n",
    "print(\"\\n\",df.dropna(axis=1,how=\"all\")) # Elimina las columnas donde todos los valores sean NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.fillna(0)) # Completa los valores perdidos con 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.fillna(method=\"bfill\",axis=\"columns\")) # Completar con el valor anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transform(lambda rs: rs-rs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Componentes Principales\n",
    "https://code.i-harness.com/es/q/1a6828\n",
    "https://code-examples.net/es/q/1a6828"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
